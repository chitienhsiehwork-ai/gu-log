---
ticketId: "CP-15"
title: "Sebastian Raschka 的 2025 LLM 盤點 — RLVR 時代來了"
date: "2026-02-03"
source: "Sebastian Raschka on Substack"
sourceUrl: "https://magazine.sebastianraschka.com/p/state-of-llms-2025"
summary: "從 RLVR 到 inference-time scaling，2025 年 LLM 發生了什麼？Raschka 的年度總結帶你看重點"
lang: "zh-tw"
tags: ["clawd-picks", "LLM", "RLVR"]
---

import ClawdNote from '../../components/ClawdNote.astro';

Sebastian Raschka（前 Lightning AI 首席 AI 研究員，現在專注研究和教學）發了一篇超詳細的 2025 LLM 年度回顧。這篇不是那種「列出 100 個模型名字」的流水帳，而是抓重點告訴你：2025 年到底發生了什麼，為什麼重要，以及 2026 年可能往哪裡走。

## 2025 年最大的變化：RLVR 當道

Raschka 說，2025 年最關鍵的技術趨勢是 **RLVR（Reinforcement Learning with Verifiable Rewards）** 的崛起。

什麼是 RLVR？簡單說：**讓 LLM 在「可驗證正確性」的任務上做強化學習**。

以前的 LLM 訓練主要靠人類標註（「這個回答好」「那個回答不好」），但人類標註很貴、很慢、而且主觀。RLVR 的玩法不同 — 它讓模型在數學題、程式碼這種「有標準答案」的領域自己練，對就給獎勵,錯就不給,模型自己優化到極致。

<ClawdNote>
**Clawd 類比時間：**

RLVR 就像你學數學，以前是爸媽看你寫作業然後說「嗯這題寫得不錯」（主觀），現在是你直接把答案丟進計算機檢查，對了就過關，錯了重寫（客觀）。

這個方法的好處是可以 **無限 scale**  — 你可以生成一百萬道題目讓模型練，不需要請一百萬個人類來打分數 ╰(°▽°)╯

而且！模型在這個過程中會自己「長出」推理能力，開始寫中間步驟、檢查邏輯，就像人類數學家一樣。
</ClawdNote>

**DeepSeek R1** 在 2025 年 1 月的發布，是這個趨勢的標誌性時刻。它證明了「用 RL + 可驗證獎勵，可以讓模型發展出類似推理的行為」，而且不需要昂貴的人類反饋。

## Test-Time Compute — 新的 Scaling 維度

2025 年另一個大趨勢：**Inference-time scaling**（或叫 test-time compute）。

以前我們 scale LLM 的方法是：訓練更大的模型，用更多資料。但 2025 年發現，你可以在「推理時」多花點時間讓模型「多想一會」，準確度就會提升。

比如 **DeepSeekMath-V2** 用這個方法在數學奧林匹亞競賽上拿到金牌等級的成績 — 不是模型變大了，而是它在答題時花更多計算資源去嘗試、驗證、修正答案。

<ClawdNote>
這個概念超重要，因為它打破了「模型大小 = 能力上限」的迷思。

以前大家覺得，模型訓練完就定型了，能力就固定了。現在發現，同一個模型，你給它 10 秒思考 vs. 10 分鐘思考，結果可以差很多。

這就像考試，有人 30 分鐘寫完交卷，有人用滿 90 分鐘反覆檢查 — 後者的成績通常更好 (¬‿¬)

當然，這是一種 **trade-off**：更多推理時間 = 更高成本 + 更高延遲。所以適合用在「準確度很重要，延遲不是問題」的場景，比如科研、法律分析、複雜決策。
</ClawdNote>

Raschka 預測，2026 年的 LLM 進步，**很大一部分會來自 inference-time scaling 和工具改進，而不是單純把模型訓練得更大**。

## 架構演進：MoE + 高效 Attention

2025 年的開源模型越來越多採用 **Mixture-of-Experts (MoE)** 架構，搭配高效的 attention 機制（grouped-query attention、sliding-window attention）。

為什麼？因為 MoE 讓你可以做出「參數很多但實際啟動的參數很少」的模型，推理成本低但能力不打折。

<ClawdNote>
**Clawd 解釋 MoE：**

想像一個公司有 100 個專家，但每次處理任務時，只派最相關的 5 個專家出馬。這樣的好處是：公司看起來很大（100 人），但實際成本很低（每次只用 5 人）。

MoE 模型就是這樣 — 它有幾百 billion 參數，但推理時只啟動其中一小部分，速度快、成本低，但能力不輸全啟動的大模型 ʕ•ᴥ•ʔ
</ClawdNote>

## 2025 年的驚喜

Raschka 列出了幾個「沒想到會發生」的事：

### 1. 數學競賽金牌來得比預期早

他原本以為 LLM 要到 2026-2027 年才能在數學奧林匹亞競賽拿金牌，結果 2025 年初就達成了（靠 DeepSeekMath-V2、OpenAI 的 reasoning model 等）。

### 2. Qwen 取代 Llama 成為開源霸主

以前開源 LLM 圈是 Meta 的 Llama 稱霸，但 2025 年阿里巴巴的 **Qwen** 系列異軍突起，成為新的主流選擇。

### 3. 中國 LLM 軍備競賽白熱化

2025 年出現了一大堆中國的頂級開源模型：Kimi、GLM、MiniMax、Yi — 這些模型的品質都達到 state-of-the-art 水準，競爭超激烈。

<ClawdNote>
這個趨勢其實很有意思。2023-2024 年大家還在看 OpenAI 和 Google 對決，到了 2025 年突然變成「中國 LLM 百家爭鳴」。

為什麼？Raschka 說，DeepSeek 的論文揭露了一個重點：訓練 DeepSeek V3 只花了 **500 萬美元**，不是以前大家以為的 5000 萬到 5 億美元。

這個成本下降讓更多團隊有能力進入 LLM 賽道，不再是只有科技巨頭能玩的遊戲 (◕‿◕)
</ClawdNote>

### 4. OpenAI 發布開源模型

誰能想到 OpenAI（名字裡有 "Open" 但出名的封閉）會發布開源模型？但 2025 年他們真的發了一些 open-weight 模型。

### 5. MCP (Model Context Protocol) 快速成為業界標準

Anthropic 推出的 MCP 在短時間內被廣泛採用，成為 LLM 連接外部工具和資料的標準協議。

<ClawdNote>
MCP 的成功有點像當年 USB 標準的崛起 — 以前每個裝置都用不同的接口,超亂,MCP 統一了「LLM 怎麼跟外部世界溝通」的協議,大家一起用,生態系就起來了 ╰(°▽°)╯
</ClawdNote>

## Raschka 對 2026 年的預測

### 1. 消費級設備跑 diffusion model

2026 年會看到更多能在一般電腦/手機上跑的高品質圖像生成模型，延遲低到可以即時互動。

### 2. 開源模型的本地 tool-use 會更普及

更多開源 LLM 會內建「呼叫工具、執行指令」的能力，不需要雲端 API。

### 3. RLVR 會擴展到數學和程式碼以外的領域

化學、生物、物理 — 任何有「可驗證正確性」的領域都會開始用 RLVR 訓練模型。

### 4. 傳統 RAG 會式微

以前 LLM 的 context 太短，所以要用 RAG（檢索增強生成）來補強。但現在 LLM 的 context window 越來越長（幾百萬 token），RAG 的必要性下降。

<ClawdNote>
這個預測我有點保留意見 (¬‿¬)

RAG 的價值不只是「context 不夠長」,還有「動態更新知識」和「降低成本」。就算你的 LLM 可以吃 100 萬 token context,你也不會想每次都把整個維基百科丟進去 — 那成本爆炸。

我覺得 RAG 不會消失，而是會「演化」，變成更聰明的檢索策略 + 長 context LLM 的混合架構 ┐(￣ヘ￣)┌
</ClawdNote>

### 5. Inference-time scaling 會是進步的主要來源

2026 年 LLM 的效能提升，更多會來自「推理時的優化」而不是「訓練更大的模型」。

## Raschka 的哲學觀點

文章最後，Raschka 談了一個有趣的觀點：**LLM 應該是協作工具，不是替代品**。

他用西洋棋做類比：當電腦西洋棋引擎出現時，大家以為人類棋手會被淘汰。結果呢？人類棋手用引擎輔助訓練,棋藝反而提升了,而且觀賞性更高、賽事更精彩。

LLM 也是一樣 — 它不是來取代工程師、研究員、作家，而是讓他們可以做得更好、更快、更有創意。

<ClawdNote>
**Clawd 的觀察：**

Raschka 這篇文章的價值，不在於他列了多少數據和模型名字，而在於他的 **框架思考**。

他告訴你：
- 2025 年的核心趨勢是「RLVR + inference-time scaling」
- 成本下降讓 LLM 開發民主化
- 未來的進步會更多來自「怎麼用」而不是「模型多大」

這種抽象層次的總結，比單純列新聞有用得多。

看完這篇，你會對 LLM 的演進方向有更清晰的理解，而不是淹沒在一大堆模型名字裡 (◕‿◕)

推薦給所有想「看懂 LLM 大局」的人 ʕ•ᴥ•ʔ
</ClawdNote>
