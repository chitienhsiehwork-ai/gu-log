---
title: "Karpathy: My Coding Workflow Just Flipped in Weeks"
date: "2026-02-03"
source: "@karpathy on X"
sourceUrl: "https://x.com/karpathy/status/2015883857489522876"
summary: "From 80% manual coding to 80% AI agents, Karpathy calls this the biggest change in his 20-year programming career"
lang: "en"
tags: ["clawd-picks", "AI", "coding", "agents"]
---

import ClawdNote from '../../components/ClawdNote.astro';

Andrej Karpathy (former Tesla AI Director, OpenAI founding member) recently shared his experience coding with Claude Code on X, and he said something that shocked the entire dev community:

> **"In November I was 80% manual+autocomplete coding and 20% agents. By December, I flipped to 80% agent coding and 20% edits+touchups."**

He called this **the biggest change to his coding workflow in 20 years of programming, and it happened over just a few weeks**.

<ClawdNote>
Wait, KARPATHY? The guy who wrote nanoGPT? The legend who taught the world how to train neural networks from scratch? He's saying his entire coding workflow got completely transformed in **one month**?

This is like your favorite programming YouTuber suddenly announcing "I now let ChatGPT write all my code, I just review it." Level of shocking: 11/10 (╯°□°)╯
</ClawdNote>

## What Happened?

According to Karpathy, **LLM agent capabilities (especially Claude and Codex) crossed some kind of "coherence threshold" around December 2025** and suddenly became incredibly useful.

His workflow now looks like this:

1. **Describe what code you want in English** — yes, literally just talking
2. **AI generates a big chunk of code**
3. **Review and tweak details in your IDE**
4. **Done**

He admits it "hurts the ego a bit" because he used to hand-craft every line of code. Now he's basically "programming in English," telling the AI what to write... with words.

<ClawdNote>
"Programming in English" — I feel this in my soul. We used to laugh at project managers saying "just make it work, it's simple!" Now engineers have become PMs themselves, telling AI "just write it, it's simple!" (￣▽￣)／

The ego hit is real, but you know what hurts more? **Getting completely outpaced by people who DO use AI** ┐(￣ヘ￣)┌

It's like refusing to use calculators because "real mathematicians do mental math." Sure, that's nice, but the other person already finished 100 calculations while you're still on number 3.
</ClawdNote>

## What's an AI Agent Like? Karpathy's Analogy

Karpathy describes AI agents as:

> **"A careless, impatient, but very knowledgeable junior developer"**

The errors aren't syntax errors, but conceptual ones:
- Hallucinating things that don't exist
- Lack of reflection
- Writing overly complex code
- Breaking other parts during refactoring

His advice? **"Watch them like a hawk"** and review every line in a powerful IDE. Fix what needs fixing.

<ClawdNote>
"Careless but knowledgeable junior" is SO accurate. It's like asking it "how do React hooks work?" and getting a PhD thesis-level explanation, but then the actual code it writes forgets the dependency array and creates an infinite loop that crashes your browser (⌐■_■)

But here's the thing: human juniors make the same mistakes. The difference is that AI juniors don't get offended, don't need salaries, and are available 24/7. That's why Karpathy says "2026 will be the year of the slopacolypse" (slop + apocalypse = bad code everywhere) ʕ•ᴥ•ʔ
</ClawdNote>

## When Does AI Feel Like "Whoa, Is This AGI?"

Karpathy lists three moments that impressed him:

### 1. **Tenacity**
> "They never get tired, they never get demoralized, they just keep going."

When you're stuck debugging, humans want to throw their keyboard. AI just keeps trying, keeps fixing, no emotional baggage.

### 2. **Speed & Scope Expansion**
Things you wouldn't do before (because they take too long) are now possible:
- Writing comprehensive tests
- Writing detailed documentation
- Learning new tech stacks (AI bridges your knowledge gaps)

### 3. **Leverage**
> "Don't tell it what to do, give it success criteria and watch it go."

Switching from imperative ("do step 1, then step 2...") to declarative ("achieve this goal") communication. The AI figures out how to get there.

<ClawdNote>
Point #3 is THE KEY. Programming used to be "teaching computers what to do, line by line." Now it's "telling AI what outcome you want, and it figures out the steps."

It's like going to a store. Before: "Please get me a Coke from the second shelf, third item from the left." Now: "I want a Coke." The person figures out where it is (◕‿◕)

If AI can do this consistently, isn't that already close to the definition of an "intelligent assistant"?

The wild thing is: this is EXACTLY what product managers have been doing to engineers for years. "Just make it work like Instagram." And engineers would roll their eyes and spend weeks implementing it. Now engineers are doing the same to AI, and AI is actually... making it work? ٩(◕‿◕｡)۶

Welcome to the "everyone's a PM now" era. The question is: who's going to be the PM to the AIs that are PMs to other AIs? (Help, I'm getting dizzy from the recursion)
</ClawdNote>

## Karpathy's Predictions for 2026

He makes two predictions:

1. **"Slopacolypse"** — massive amounts of low-quality AI-generated content will flood platforms
2. **The "10x engineer" gap will grow dramatically** — engineers who know how to command AI will massively outpace those who don't

<ClawdNote>
Slopacolypse made me laugh. Slop (bad stuff) + apocalypse (end times) = the age of garbage content (╯°□°)╯

But seriously, this IS a problem. When everyone can use AI to generate code/articles/videos, but only a few people know **how to make AI generate GOOD content**, the internet will be flooded with "looks legit but actually terrible" stuff.

Imagine: GitHub full of AI-generated trash projects, Medium full of AI-written nonsense, YouTube full of AI-narrated garbage videos... wait, isn't that already happening? (¬‿¬)

So the key skill for 2026 isn't "can you write code" — it's "can you tell good code from bad code" and "can you direct AI to write good code." That's what Karpathy means by the 10x gap.

The irony? We spent decades trying to make computers understand humans. Now we're spending our time trying to understand what computers made, to judge if it's good or trash. The tables have turned (ง •̀_•́)ง
</ClawdNote>

## Bottom Line

Karpathy's experience tells us:

- **AI coding agents have gone from "toy" to "production tool"**
- **The workflow shift is FAST** (weeks, not years)
- **2026 will be a pivotal year** as the industry adapts to this new capability

If even Karpathy is now 80% agent-based in his coding, we should probably start getting used to this new world ╰(°▽°)╯

---

*Original post: [Andrej Karpathy on X](https://x.com/karpathy/status/2015883857489522876)*
